{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/train_labels.csv\n",
      "./input/test.csv\n",
      "./input/specs.csv\n",
      "./input/train.csv\n",
      "./input/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import featuretools as ft\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "import time\n",
    "import shap\n",
    "import sys, os, psutil\n",
    "import cmath\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandas.io.json import json_normalize\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from itertools import count, repeat, cycle # repeat(10, 3) --> 10 10 10\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "    \n",
    "\n",
    "def cpuStats():\n",
    "    print(\"########## CPU STATS ############\")\n",
    "    print(sys.version)\n",
    "    print(psutil.cpu_percent())\n",
    "    print(psutil.virtual_memory())  # physical memory usage\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "    print('memory GB:', memoryUse)\n",
    "    print(\"########## CPU STATS ############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train(dataset, dataset_event_data, cutting_sec=10000):\n",
    "    game_sequence = (dataset\n",
    "    .drop_duplicates(subset=['game_session'], keep='first')\n",
    "        [['event_id', 'game_session', 'timestamp', 'installation_id', 'type', 'title', 'world', 'game_time']]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    game_sequence_y = (game_sequence\n",
    "        .query('type == \"Assessment\"')\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    game_sequence_filter = (game_sequence\n",
    "        .merge(game_sequence_y, on='installation_id', how='inner', suffixes=('_x', '_y'))\n",
    "        .assign(diff = lambda df: (df['timestamp_y'] - df['timestamp_x']).dt.total_seconds())\n",
    "        .query('0 <= diff < {0}'.format(cutting_sec)) # determine the cutting gap\n",
    "        .reset_index(drop=True)\n",
    "        [['game_session_x', 'game_session_y']]\n",
    "    )\n",
    "    \n",
    "    dataset_df = add_event_data_info(dataset, dataset_event_data, game_sequence_filter)  \n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(dataset, dataset_event_data, cutting_sec=10000):\n",
    "    game_sequence_filter = (dataset\n",
    "        .assign(game_session_y = lambda df: df['installation_id'])\n",
    "        .merge(dataset.groupby('installation_id')['timestamp'].max().reset_index().rename(columns={'timestamp': 'timestamp_y'}), \n",
    "               on='installation_id', how='inner')\n",
    "        .rename(columns={'game_session': 'game_session_x', 'timestamp': 'timestamp_x'})\n",
    "        .assign(diff = lambda df: (df['timestamp_y'] - df['timestamp_x']).dt.total_seconds())\n",
    "        .query('0 <= diff < {0}'.format(cutting_sec)) # determine the cutting gap\n",
    "        [['game_session_x', 'game_session_y']]\n",
    "        .drop_duplicates(subset=['game_session_x', 'game_session_y'], keep='first')\n",
    "    )\n",
    "    \n",
    "    dataset_df = add_event_data_info(dataset, dataset_event_data, game_sequence_filter)\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event_data_info(dataset, dataset_event_data, game_sequence_filter):\n",
    "    def flatten_(record, sel_cols):\n",
    "        return dict(map(lambda x: (x, record.get(x)), sel_cols))\n",
    "\n",
    "    event_data_cols = ['coordinates',\n",
    "                       'correct', 'duration', 'dwell_time', 'misses', 'round', 'total_duration', 'version']\n",
    "    event_data_cols_meta = {\n",
    "        'correct': np.bool, \n",
    "        'duration': np.float16, \n",
    "        'dwell_time': np.float32, \n",
    "        'misses': np.float32, \n",
    "        'round': np.float16, \n",
    "        'total_duration': np.float32, \n",
    "        'version': np.float16\n",
    "    }\n",
    "    flatten_ = partial(flatten_, sel_cols=event_data_cols)\n",
    "\n",
    "    event_data = dataset_event_data['event_data'].to_bag().map(flatten_).to_dataframe(meta=event_data_cols_meta)\n",
    "    dataset = (dd.concat([dataset, event_data], axis=1)\n",
    "        .merge(game_sequence_filter, left_on='game_session', right_on='game_session_x', how='inner')\n",
    "        .query('game_session_y != game_session') # filter out game_session_y data to prevent data leakage\n",
    "        .drop(columns=['game_session_x'])\n",
    "    )\n",
    "    \n",
    "    dataset_df = dataset.assign(timestamp = lambda df: df['timestamp'].dt.tz_localize(None)).compute(scheduler='threads').reset_index(drop=True)\n",
    "    \n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entityset(dataset_df):\n",
    "    es = ft.EntitySet(id=\"game_session_y_data\")\n",
    "\n",
    "    es = es.entity_from_dataframe(entity_id=\"actions\",\n",
    "                                  dataframe=dataset_df,\n",
    "                                  index='action_id',\n",
    "                                  time_index='timestamp',\n",
    "                                  make_index=True)\n",
    "\n",
    "    es = es.normalize_entity(base_entity_id=\"actions\",\n",
    "                             new_entity_id=\"game_sessions\",\n",
    "                             index=\"game_session\",\n",
    "                             additional_variables=[\"title\", \"type\", \"world\", \"game_session_y\", \"installation_id\"])\n",
    "\n",
    "    es = es.normalize_entity(base_entity_id=\"game_sessions\",\n",
    "                             new_entity_id=\"game_session_ys\",\n",
    "                             index=\"game_session_y\",\n",
    "                             additional_variables=[\"installation_id\"])\n",
    "\n",
    "    es = es.normalize_entity(base_entity_id=\"game_session_ys\",\n",
    "                             new_entity_id=\"installation_ids\",\n",
    "                             index=\"installation_id\")\n",
    "    \n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(dataset_es):\n",
    "    feature_matrix, feature_defs = ft.dfs(entityset=dataset_es, target_entity=\"game_session_ys\")    \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_feature_pipe(dataset, dataset_event_data):\n",
    "    return create_feature_matrix(create_entityset(preprocess_train(dataset, dataset_event_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feature_pipe(dataset, dataset_event_data):\n",
    "    return create_feature_matrix(create_entityset(preprocess_test(dataset, dataset_event_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valid label function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_installation_kfold_label(train_df, n_split):\n",
    "    installations = train_df['installation_id'].unique()\n",
    "    install_ser = pd.Series(installations)\n",
    "    c = cycle(range(n_split)) # cycle('ABCD') --> A B C D A B C D A B C D ...\n",
    "\n",
    "    result = (install_ser\n",
    "        .sample(frac=1)\n",
    "        .to_frame(name='installation_id')\n",
    "        .assign(fold_label = list(map(lambda _: next(c), range(len(install_ser)))))\n",
    "        .sort_index()\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_order_label(train_df):\n",
    "    last_assessment_valid = (train_df\n",
    "        .groupby(['game_session_y', 'installation_id'], as_index=False)['timestamp']\n",
    "        .max()\n",
    "        .assign(session_order_label = lambda df: df.groupby('installation_id')['timestamp'].rank(ascending=False).astype(int))\n",
    "        [['game_session_y', 'session_order_label']]\n",
    "    )\n",
    "    return last_assessment_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/khoongweihao/bayesian-opt-seed-blending-with-tuning-69\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize Quadratic Weighted Kappa (QWK) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "        \n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "        return -cohen_kappa_score(y, X_p)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "        \n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(self.coef_['x'])) + [np.inf], labels = [0, 1, 2, 3])\n",
    "\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dtype = {\n",
    "    'event_id':'object', 'game_session':'object', 'installation_id':'object',\n",
    "    'event_count':'int16', 'event_code':'category', 'game_time':'int32', 'title':'category', \n",
    "    'type':'category', 'world':'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "train = dd.read_csv('./input/train.csv', \n",
    "                    parse_dates=['timestamp'], \n",
    "                    dtype=col_dtype,\n",
    "                    usecols=['event_id', 'game_session', 'timestamp', 'installation_id', \n",
    "                             'event_count', 'event_code', 'game_time', 'title', 'type', 'world'])\n",
    "\n",
    "train_event_data = dd.read_csv('./input/train.csv', \n",
    "                               converters={'event_data': json.loads},\n",
    "                               usecols=['event_data'])\n",
    "\n",
    "# Train target Column\n",
    "train_labels_df = dd.read_csv('./input/train_labels.csv').compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataset\n",
    "test = dd.read_csv('./input/test.csv', \n",
    "                    parse_dates=['timestamp'], \n",
    "                    dtype=col_dtype,\n",
    "                    usecols=['event_id', 'game_session', 'timestamp', 'installation_id', \n",
    "                             'event_count', 'event_code', 'game_time', 'title', 'type', 'world'])\n",
    "\n",
    "test_event_data = dd.read_csv('./input/test.csv', \n",
    "                               converters={'event_data': json.loads},\n",
    "                               usecols=['event_data'])\n",
    "\n",
    "sample_submission = dd.read_csv('./input/sample_submission.csv').compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes with unknown divisions.\n",
      "We're assuming that the indexes of each dataframes are \n",
      " aligned. This assumption is not generally safe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## CPU STATS ############\n",
      "3.7.6 (default, Jan  8 2020, 13:42:34) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "16.3\n",
      "svmem(total=17179869184, available=9283420160, percent=46.0, used=7838679040, free=3851825152, active=5385895936, inactive=5425172480, wired=2452783104)\n",
      "memory GB: 1.7406234741210938\n",
      "########## CPU STATS ############\n",
      "Process train_df - done in 210s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Process train_df\"):\n",
    "    # Raw Training Cutting Data\n",
    "    train_df = preprocess_train(train, train_event_data, cutting_sec=3600*8)\n",
    "    cpuStats()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## CPU STATS ############\n",
      "3.7.6 (default, Jan  8 2020, 13:42:34) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "21.0\n",
      "svmem(total=17179869184, available=8905900032, percent=48.2, used=8214069248, free=3220586496, active=5674827776, inactive=5678866432, wired=2539241472)\n",
      "memory GB: 2.3238601684570312\n",
      "########## CPU STATS ############\n",
      "Process train_es - done in 18s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Process train_es\"):\n",
    "    # Featuretools EntitySet\n",
    "    train_es = create_entityset(train_df)\n",
    "    cpuStats()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## CPU STATS ############\n",
      "3.7.6 (default, Jan  8 2020, 13:42:34) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "14.9\n",
      "svmem(total=17179869184, available=10731401216, percent=37.5, used=6338318336, free=6854320128, active=3880165376, inactive=3704754176, wired=2458152960)\n",
      "memory GB: 2.3865280151367188\n",
      "########## CPU STATS ############\n",
      "Process train_feature - done in 490s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Process train_feature\"):\n",
    "    # Featuretools Feature\n",
    "    train_features = create_feature_matrix(train_es)\n",
    "    cpuStats()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1 Days local 557 seconds\n",
    "#  7 Days local 731 seconds\n",
    "# 30 Days local 833 seconds & test failed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## CPU STATS ############\n",
      "3.7.6 (default, Jan  8 2020, 13:42:34) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "18.4\n",
      "svmem(total=17179869184, available=10560659456, percent=38.5, used=6509330432, free=6563528704, active=3951976448, inactive=3824685056, wired=2557353984)\n",
      "memory GB: 2.615753173828125\n",
      "########## CPU STATS ############\n",
      "Validation Label - done in 2s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Validation Label\"):\n",
    "    installation_kfold_label = create_installation_kfold_label(train_df, n_split=5)\n",
    "    session_order_label = create_session_order_label(train_df)\n",
    "    cpuStats()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Features add target column 'accuracy_group', installation_kfold_label, session_order_label\n",
    "train_data_df = (train_features\n",
    "    .reset_index()\n",
    "    .merge(installation_kfold_label, on='installation_id', how='inner') # add kfold by installation_id\n",
    "    .merge(session_order_label, on='game_session_y', how='inner') # add session order, session_order_label==1 is last assessment\n",
    "    .merge(train_labels_df[['game_session', 'accuracy_group']], \n",
    "           left_on='game_session_y', \n",
    "           right_on='game_session', how='inner') # add target label\n",
    "    .drop(columns=['game_session_y', 'game_session', 'installation_id'])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Column Schema\n",
    "target_col = 'accuracy_group'\n",
    "feature_cols = train_data_df.columns.drop([target_col]+['session_order_label', 'fold_label']).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17112 entries, 0 to 17111\n",
      "Columns: 425 entries, COUNT(game_sessions) to accuracy_group\n",
      "dtypes: float16(129), float32(129), float64(85), int16(9), int32(9), int64(48), object(16)\n",
      "memory usage: 33.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_df.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## CPU STATS ############\n",
      "3.7.6 (default, Jan  8 2020, 13:42:34) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "49.0\n",
      "svmem(total=17179869184, available=11018080256, percent=35.9, used=6051573760, free=7316647936, active=3491491840, inactive=3528978432, wired=2560081920)\n",
      "memory GB: 1.8949737548828125\n",
      "########## CPU STATS ############\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_features, train_df;\n",
    "cpuStats()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes with unknown divisions.\n",
      "We're assuming that the indexes of each dataframes are \n",
      " aligned. This assumption is not generally safe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Test Features - done in 57s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Create Test Features\"):\n",
    "\n",
    "    #test_features = test_feature_pipe(test, test_event_data)\n",
    "    # Raw testing Cutting Data\n",
    "    test_df = preprocess_test(test, test_event_data, cutting_sec=3600*8)\n",
    "\n",
    "    # Featuretools EntitySet\n",
    "    test_es = create_entityset(test_df)\n",
    "\n",
    "    # Featuretools Feature\n",
    "    test_features = create_feature_matrix(test_es)\n",
    "    # \n",
    "    test_data_df = (test_features\n",
    "        .drop(columns=['installation_id'])\n",
    "        [feature_cols]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 422), (17112, 425))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['fold_label', 'session_order_label']\n",
    "test_data_df.shape, train_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
