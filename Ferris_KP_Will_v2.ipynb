{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/train_labels.csv\n",
      "./input/test.csv\n",
      "./input/specs.csv\n",
      "./input/train.csv\n",
      "./input/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import featuretools as ft\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from functools import partial\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import shap\n",
    "\n",
    "import sys, os, psutil\n",
    "\n",
    "import cmath\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "    \n",
    "    \n",
    "def cpuStats():\n",
    "    print(\"########## CPU STATS ############\")\n",
    "    print(sys.version)\n",
    "    print(psutil.cpu_percent())\n",
    "    print(psutil.virtual_memory())  # physical memory usage\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "    print('memory GB:', memoryUse)\n",
    "    print(\"########## CPU STATS ############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dtype = {\n",
    "    'event_id':'object', 'game_session':'object', 'installation_id':'object',\n",
    "    'event_count':'int16', 'event_code':'category', 'game_time':'int32', 'title':'category', \n",
    "    'type':'category', 'world':'category'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "train = dd.read_csv('./input/train.csv', \n",
    "                    parse_dates=['timestamp'], \n",
    "                    dtype=col_dtype,\n",
    "                    usecols=['event_id', 'game_session', 'timestamp', 'installation_id', \n",
    "                             'event_count', 'event_code', 'game_time', 'title', 'type', 'world'])\n",
    "\n",
    "train_event_data = dd.read_csv('./input/train.csv', \n",
    "                               converters={'event_data': json.loads},\n",
    "                               usecols=['event_data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_df = dd.read_csv('./input/train_labels.csv').compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dd.read_csv('./input/test.csv', \n",
    "                    parse_dates=['timestamp'], \n",
    "                    dtype=col_dtype,\n",
    "                    usecols=['event_id', 'game_session', 'timestamp', \n",
    "                             'installation_id', 'event_count', 'event_code', \n",
    "                             'game_time', 'title', 'type', 'world'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_sequence = (train\n",
    "    .drop_duplicates(subset=['game_session'], keep='first')\n",
    "    [['event_id', 'game_session', 'timestamp', 'installation_id', 'type', 'title', 'world', 'game_time']]\n",
    "    .reset_index(drop=True)\n",
    "    #.assign(diff_sec = lambda df: df.groupby('installation_id')['timestamp'].transform(lambda x: x.diff()).dt.total_seconds().fillna(0))\n",
    ")\n",
    "\n",
    "game_sequence_y = (game_sequence\n",
    "    .query('type == \"Assessment\"')\n",
    "    #[['event_id', 'game_session', 'timestamp', 'installation_id', 'event_code', 'title', 'type', 'world', 'game_time']]\n",
    "    .reset_index(drop=True)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "game_sequence_filter = (game_sequence\n",
    "    .merge(game_sequence_y, on='installation_id', how='inner', suffixes=('_x', '_y'))\n",
    "    .assign(diff = lambda df: (df['timestamp_y'] - df['timestamp_x']).dt.total_seconds())\n",
    "    .query('0 <= diff < 604800')#\n",
    "    .reset_index(drop=True)\n",
    "    [['game_session_x', 'game_session_y', 'title_y', 'world_y', 'game_time_y']]\n",
    ")#.compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Event Data - done in 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes with unknown divisions.\n",
      "We're assuming that the indexes of each dataframes are \n",
      " aligned. This assumption is not generally safe.\n"
     ]
    }
   ],
   "source": [
    "def flatten(record, sel_cols):\n",
    "    return dict(map(lambda x: (x, record.get(x)), sel_cols))\n",
    "\n",
    "event_data_cols = ['coordinates',\n",
    "                   'correct', 'duration', 'dwell_time', 'misses', 'round', 'total_duration', 'version']\n",
    "event_data_cols_meta = {\n",
    "    'correct': np.bool, \n",
    "    'duration': np.float16, \n",
    "    'dwell_time': np.float32, \n",
    "    'misses': np.float32, \n",
    "    'round': np.float16, \n",
    "    'total_duration': np.float32, \n",
    "    'version': np.float16\n",
    "}\n",
    "\n",
    "\n",
    "with timer(\"Process Event Data\"):\n",
    "\n",
    "    flatten = partial(flatten, sel_cols=event_data_cols)\n",
    "\n",
    "    event_data = train_event_data['event_data'].to_bag().map(flatten).to_dataframe(meta=event_data_cols_meta)\n",
    "    train = (dd.concat([train, event_data], axis=1)\n",
    "        .merge(game_sequence_filter, left_on='game_session', right_on='game_session_x', how='inner')\n",
    "        .query('game_session_y != game_session')\n",
    "        .drop(columns=['game_session_x'])\n",
    "    )\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer(\"Process train_df\"):\n",
    "\n",
    "    train_df = train.compute(scheduler='threads').reset_index(drop=True)\n",
    "    print(train_df.shape)\n",
    "    cpuStats()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37230923, 21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing\n",
    "- `correct`\n",
    "    - 尚未驗證：與目標關聯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    35425335\n",
       "True      1805588\n",
       "Name: correct, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['action_id', 'event_id', 'game_session', 'timestamp', 'installation_id',\n",
       "       'event_count', 'event_code', 'game_time', 'title', 'type', 'world',\n",
       "       'correct', 'duration', 'dwell_time', 'misses', 'round',\n",
       "       'total_duration', 'version', 'game_session_y', 'title_y', 'world_y',\n",
       "       'game_time_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id=\"game_session_y_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.entity_from_dataframe(entity_id=\"actions\",\n",
    "                              dataframe=train_df,\n",
    "                              index='action_id',\n",
    "                              make_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.normalize_entity(base_entity_id=\"actions\",\n",
    "                         new_entity_id=\"game_sessions\",\n",
    "                         index=\"game_session\",\n",
    "                         additional_variables=[\"title\", \"type\", \"world\",\n",
    "                                               \"game_session_y\", \"title_y\", \"world_y\", \"installation_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.normalize_entity(base_entity_id=\"game_sessions\",\n",
    "                         new_entity_id=\"game_session_ys\",\n",
    "                         index=\"game_session_y\",\n",
    "                         additional_variables=[\"title_y\", \"world_y\", \"installation_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.normalize_entity(base_entity_id=\"game_session_ys\",\n",
    "                         new_entity_id=\"installation_ids\",\n",
    "                         index=\"installation_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer(\"Process Feature Matrix\"):\n",
    "\n",
    "    feature_matrix, feature_defs = ft.dfs(entityset=es,\n",
    "                                      target_entity=\"game_session_ys\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer(\"Process Train Data DF\"):\n",
    "\n",
    "    train_data_df = (feature_matrix\n",
    "        .merge(train_labels_df[['game_session', 'accuracy_group']], \n",
    "               left_index=True, right_on='game_session', how='inner')\n",
    "        .drop(columns=['game_session', 'installation_id'])\n",
    "#         .reset_index(drop=True)\n",
    "        )\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['PERCENT_TRUE(actions.correct)', 'SUM(game_sessions.PERCENT_TRUE(actions.correct))', 'STD(game_sessions.PERCENT_TRUE(actions.correct))', 'MAX(game_sessions.PERCENT_TRUE(actions.correct))', 'SKEW(game_sessions.PERCENT_TRUE(actions.correct))', 'MIN(game_sessions.PERCENT_TRUE(actions.correct))', 'MEAN(game_sessions.PERCENT_TRUE(actions.correct))', 'installation_ids.PERCENT_TRUE(actions.correct)']"
      ],
      "text/plain": [
       "['PERCENT_TRUE(actions.correct)',\n",
       " 'SUM(game_sessions.PERCENT_TRUE(actions.correct))',\n",
       " 'STD(game_sessions.PERCENT_TRUE(actions.correct))',\n",
       " 'MAX(game_sessions.PERCENT_TRUE(actions.correct))',\n",
       " 'SKEW(game_sessions.PERCENT_TRUE(actions.correct))',\n",
       " 'MIN(game_sessions.PERCENT_TRUE(actions.correct))',\n",
       " 'MEAN(game_sessions.PERCENT_TRUE(actions.correct))',\n",
       " 'installation_ids.PERCENT_TRUE(actions.correct)']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in train_data_df.columns if 'correct' in i ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "xx = 'MAX(game_sessions.PERCENT_TRUE(actions.correct))'\n",
    "a = train_data_df[xx]\n",
    "b = train_data_df.accuracy_group\n",
    "corr, _ = pearsonr(a, b)\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
